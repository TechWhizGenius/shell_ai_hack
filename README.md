## ğŸ”— Competition Details

<div align="center">

### ğŸ“ **Event Information**

[![HackerEarth](https://img.shields.io/badge/Platform-HackerEarth-green?style=for-the-badge&logo=hackerearth)](https://www.hackerearth.com/challenges/new/competitive/shellai-hackathon-2025/)
[![Shell.ai](https://img.shields.io/badge/Organizer-Shell.ai-yellow?style=for-the-badge&logo=shell)](https://www.shell.com/what-we-do/digitalisation/collaboration-and-open-innovation/shell-ai-hackathon-for-sustainable-and-affordable-energy.html)

</div>

| **Attribute** | **Details** |
|---------------|-------------|
| **ğŸ¢ Organizer** | Shell.ai Team |
| **ğŸŒ Platform** | [HackerEarth](https://www.hackerearth.com/challenges/new/competitive/shellai-hackathon-2025/) |
| **ğŸ“… Competition Period** | Jul 04, 2025 - Jul 23, 2025 |
| **ğŸ‘¥ Total Participants** | 7,005 |
| **ğŸ¯ Challenge Focus** | Sustainable Fuel Blend Properties Prediction |
| **ğŸ“Š Submission Limit** | 2000 total, 100 per day |
| **ğŸ† Prize Categories** | General, University, Start-up Editions |

---

### ğŸ› ï¸ **Tech Stack**

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)

</div>

*Special appreciation for the open-source data science ecosystem that made this project possible*

---
## ğŸŒ Introduction
Welcome to the sixth edition of the Shell.ai Hackathon for Sustainable and Affordable Energy. Shell.ai Hackathon brings together brilliant minds passionate about digital solutions and AI, to tackle real energy challenges and help build a lower-carbon world where everyone can access and afford energy.

## ğŸš€ Challenge

> *"Accelerating the transition to a net-zero future without compromising on excellence"*

The global call for sustainability is reshaping every industry, including mobility, shipping and aviation. Sustainable Aviation Fuels (SAFs) are pivotal in this transformation, offering a powerful lever to significantly reduce the sector's environmental footprint. However, integrating these innovative fuels into the existing ecosystem presents a sophisticated challenge.

Crafting the optimal fuel blend â€“ mixing various sustainable fuel types sourced from diverse pathways with each other or with conventional fuels â€“ is an intricate science. It demands a delicate balancing act: ensuring adherence to rigorous safety and performance specifications while maximizing environmental benefits and maintaining economic viability.


## ğŸ¯ Problem Statement

In the fuel industry, blending different fuel components to achieve desired properties is both an art and a science. The relationships between component fractions and final blend properties are highly complex, involving linear and non-linear interactions, synergistic effects, and conditional behaviours that vary based on component combinations. This complexity makes accurate prediction a challenging, high-dimensional problem.

The challenge is to develop models capable of accurately predicting the properties of fuel blends based on their constituent components and their proportions. These predictions must be precise enough to guide real-world blending decisions where safety, performance, and sustainability are paramount. By harnessing the power of data science and machine learning, this work helps accelerate the adoption of sustainable aviation fuels by providing tools that can rapidly evaluate thousands of potential blend combinations, identify optimal recipes that maximize sustainability while meeting specifications, reduce development time for new sustainable fuel formulations, and enable real-time blend optimization in production facilities.
---

## ğŸ“Š Dataset Overview

The competition provided **three key files** with rich, complex data:

<div align="center">

```mermaid
graph LR
    A[ğŸ“ train.csv] --> B[ğŸ§  Model Training]
    C[ğŸ“ test.csv] --> D[ğŸ¯ Predictions]
    E[ğŸ“ sample_submission.csv] --> F[ğŸ“¤ Submission Format]
    B --> D
    D --> F
```

</div>

### ğŸ“ˆ `train.csv` - Training Data

<div align="center">
  
**ğŸ² Total Columns: 65**

</div>

| **Section** | **Columns** | **Description** | **Format** |
|-------------|-------------|-----------------|------------|
| ğŸ§ª **Blend Composition** | `5` | Volume percentage of each base component | `Component1` to `Component5` |
| ğŸ”¬ **Component Properties** | `50` | Certificate of Analysis (COA) data for each component batch | `Component{N}_Property{M}` |
| ğŸ¯ **Target Variables** | `10` | Final blend properties to predict | `BlendProperty1` to `BlendProperty10` |

> **ğŸ“ Note**: Component properties follow the structure `Component{1-5}_Property{1-10}` 
> 
> *Example: `Component1_Property1`, `Component2_Property5`, etc.*

---

### ğŸ§ª `test.csv` - Evaluation Data


- **500 test samples** with 55 input features (composition + component properties)
- **âŒ No target variables** - these needed to be predicted

---

### ğŸ“‹ `sample_submission.csv` - Submission Template

```csv
ID,BlendProperty1,BlendProperty2,...,BlendProperty10
1,12.34,56.78,...,90.12
2,23.45,67.89,...,01.23
...
```

## ğŸ“ Evaluation Methodology

<div align="center">

### ğŸ¯ **Primary Metric: Mean Absolute Percentage Error (MAPE)**

</div>

```python
# Mathematical Formula
MAPE = (100/n) Ã— Î£|((actual - predicted) / actual)|

# Leaderboard Score Calculation  
Score = max(0, 100 Ã— (1 - cost/reference_cost))
```

---

</div>

## ğŸ› ï¸ My Approach

<div align="center">

### ğŸš€ **Solution Architecture**

</div>

<details>
<summary><b>ğŸ” Data Preprocessing</b></summary>

- [ ] **Data Cleaning**: [Describe your data cleaning steps]
- [ ] **Feature Engineering**: [Feature engineering techniques used]  
- [ ] **Missing Values**: [Handling of missing values, outliers, etc.]
- [ ] **Scaling/Normalization**: [Any normalization techniques applied]

```python
# Example preprocessing pipeline
def preprocess_data(df):
    # Your preprocessing steps here
    return processed_df
```

</details>

<details>
<summary><b>ğŸ§  Model Development</b></summary>

#### Algorithms Experimented With:
- [ ] **Linear Models**: Ridge, Lasso, ElasticNet
- [ ] **Tree-based**: Random Forest, XGBoost, LightGBM
- [ ] **Neural Networks**: Multi-layer perceptrons
- [ ] **Ensemble Methods**: Voting, Stacking

#### Feature Selection:
- [ ] **Statistical Tests**: [Methods used]
- [ ] **Feature Importance**: [From tree-based models]
- [ ] **Correlation Analysis**: [Remove highly correlated features]

#### Cross-validation Strategy:
```python
# Example CV strategy
from sklearn.model_selection import KFold
cv = KFold(n_splits=5, shuffle=True, random_state=42)
```

</details>

<details>
<summary><b>âš™ï¸ Key Technical Decisions</b></summary>

| Decision | Rationale | Impact |
|----------|-----------|--------|
| **Model Choice** | [Why you chose your final model] | [Performance impact] |
| **Feature Engineering** | [Key feature engineering decisions] | [Impact on model performance] |
| **Hyperparameter Tuning** | [Approach used] | [Improvement achieved] |

</details>

### ğŸ—ï¸ Final Model Architecture

<div align="center">

```mermaid
graph TD
    A[ğŸ“Š Raw Data] --> B[ğŸ”§ Preprocessing]
    B --> C[ğŸ¯ Feature Engineering]
    C --> D[ğŸ§  Model Training]
    D --> E[ğŸ”„ Cross Validation]
    E --> F[âš™ï¸ Hyperparameter Tuning]
    F --> G[ğŸ¯ Final Predictions]
```

</div>

**ğŸ“ˆ Performance Metrics Achieved:**
- **Training MAPE**: [Your score]
- **Validation MAPE**: [Your score]
- **Cross-validation Score**: [Your score]

## ğŸ“ Repository Structure

```
ğŸ“¦ shell-ai-hackathon-2025/
â”œâ”€â”€ ğŸ“Š data/                    # Dataset files (if shareable)
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ sample_submission.csv
â”œâ”€â”€ ğŸ““ notebooks/               # Jupyter notebooks for EDA and modeling
â”‚   â”œâ”€â”€ 01_exploratory_data_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_development.ipynb
â”‚   â””â”€â”€ 04_final_predictions.ipynb
â”œâ”€â”€ ğŸ src/                     # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing functions
â”‚   â”œâ”€â”€ models.py              # Model definitions
â”‚   â”œâ”€â”€ utils.py               # Utility functions
â”‚   â””â”€â”€ main.py                # Main execution script
â”œâ”€â”€ ğŸ“ˆ results/                 # Model outputs and predictions
â”‚   â”œâ”€â”€ submission.csv         # Final submission file
â”‚   â”œâ”€â”€ model_performance.json # Performance metrics
â”‚   â””â”€â”€ feature_importance.csv # Feature importance analysis
â”œâ”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
â”œâ”€â”€ ğŸ³ Dockerfile             # Docker configuration (optional)
â”œâ”€â”€ âš™ï¸ config.yaml            # Configuration parameters
â””â”€â”€ ğŸ“– README.md               # This file
```

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue?style=flat-square&logo=python)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-orange?style=flat-square&logo=jupyter)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-green?style=flat-square&logo=pandas)
![Scikit](https://img.shields.io/badge/Scikit--Learn-ML-red?style=flat-square&logo=scikit-learn)

</div>

## ğŸš€ How to Run

<div align="center">

### ğŸ”§ **Quick Start Guide**

</div>

<details>
<summary><b>ğŸ“‹ Prerequisites</b></summary>

- **Python**: 3.8 or higher
- **Operating System**: Windows/macOS/Linux
- **RAM**: Minimum 8GB (16GB recommended)
- **Storage**: ~500MB for dependencies

</details>

### 1ï¸âƒ£ **Clone the Repository**

```bash
# Clone the repository
git clone [your-repo-url]
cd shell-ai-hackathon-2025

# Verify the structure
ls -la
```

### 2ï¸âƒ£ **Set Up Environment**

<div align="center">

**Choose your preferred method:**

</div>

<div align="center">

| Using pip | Using conda | Using Docker |
|-----------|-------------|--------------|
| ![pip](https://img.shields.io/badge/pip-Install-blue?style=flat-square) | ![conda](https://img.shields.io/badge/conda-Environment-green?style=flat-square) | ![docker](https://img.shields.io/badge/Docker-Container-blue?style=flat-square) |

</div>

<details>
<summary><b>ğŸ Using pip (Recommended)</b></summary>

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

</details>

<details>
<summary><b>ğŸ Using conda</b></summary>

```bash
# Create conda environment
conda create -n shell-ai python=3.8

# Activate environment
conda activate shell-ai

# Install dependencies
pip install -r requirements.txt
```

</details>

<details>
<summary><b>ğŸ³ Using Docker</b></summary>

```bash
# Build Docker image
docker build -t shell-ai-hackathon .

# Run container
docker run -it --rm -v $(pwd):/app shell-ai-hackathon
```

</details>

### 3ï¸âƒ£ **Execute the Pipeline**

```bash
# Run the complete pipeline
python src/main.py

# Or run specific components
python src/preprocessing.py    # Data preprocessing only
python src/models.py          # Model training only
```

### 4ï¸âƒ£ **View Results**

```bash
# Check the results directory
ls results/

# View submission file
head results/submission.csv
```

<div align="center">

**ğŸ‰ Your submission file is ready at `results/submission.csv`!**

</div>

## ğŸ“ˆ Results & Learnings

<div align="center">

### ğŸ† **Competition Performance**

</div>

<div align="center">

| Metric | Score | Rank |
|--------|-------|------|
| **ğŸ¯ Final MAPE Score** | `[Your score]` | - |
| **ğŸ“Š Public Leaderboard** | `[Your position]` | `#[rank]` |
| **ğŸ”’ Private Leaderboard** | `[Your position]` | `#[rank]` |
| **ğŸ‘¥ Total Participants** | `[Total number]` | - |

</div>

---

### ğŸ§  Key Insights Discovered

<details>
<summary><b>ğŸ’¡ Data Insights</b></summary>

- **ğŸ” Pattern Discovery**: [What patterns you found in the data]
- **ğŸ“Š Feature Importance**: [Which features were most important]
- **ğŸ”— Correlations**: [Interesting correlations between components and properties]
- **âš ï¸ Data Quality**: [Any data quality issues encountered]

</details>

<details>
<summary><b>ğŸ› ï¸ Technical Learnings</b></summary>

#### âœ… **What Worked Well**
- [Successful techniques/approaches]
- [Models that performed well]
- [Effective feature engineering strategies]

#### âŒ **What Didn't Work**
- [Approaches that failed]
- [Models with poor performance]
- [Feature engineering that didn't help]

#### ğŸ”„ **Surprising Results**
- [Unexpected findings]
- [Counter-intuitive results]
- [Model behaviors that surprised you]

</details>

---

### ğŸš§ Challenges Faced

<div align="center">

| Challenge | Impact | Solution |
|-----------|--------|----------|
| **ğŸ§® High Dimensionality** | Complex feature space | [Your approach] |
| **ğŸ”— Non-linear Interactions** | Standard models struggled | [Your solution] |
| **â° Time Constraints** | Limited experimentation | [How you managed] |
| **ğŸ’¾ Computational Resources** | Model training time | [Optimization strategies] |

</div>

---

### ğŸš€ Future Improvements

<div align="center">

#### ğŸ¯ **If I Had More Time...**

</div>

<details>
<summary><b>ğŸ”¬ Advanced Modeling</b></summary>

- [ ] **Deep Learning**: Experiment with neural networks for capturing complex interactions
- [ ] **Ensemble Methods**: More sophisticated ensemble techniques
- [ ] **Feature Selection**: Advanced feature selection algorithms
- [ ] **Hyperparameter Optimization**: Bayesian optimization for better parameter tuning

</details>

<details>
<summary><b>ğŸ“Š Data Analysis</b></summary>

- [ ] **External Data**: Incorporate additional fuel property databases
- [ ] **Domain Knowledge**: Consult with fuel chemistry experts
- [ ] **Feature Engineering**: Create more sophisticated engineered features
- [ ] **Data Augmentation**: Generate synthetic training samples

</details>

<details>
<summary><b>âš™ï¸ Engineering Improvements</b></summary>

- [ ] **MLOps Pipeline**: Implement CI/CD for model deployment
- [ ] **Monitoring**: Add model performance monitoring
- [ ] **Scalability**: Optimize for larger datasets
- [ ] **Interpretability**: Add model explainability features

</details>

---

<div align="center">

### ğŸ“ **Personal Growth**

*"This hackathon taught me [your key learnings about machine learning, fuel chemistry, or technical skills]*"

</div>

## ğŸ™ Acknowledgments

- Shell.ai team for organizing this impactful hackathon
- The sustainable energy community for inspiration
- [Any other acknowledgments]

<div align="center">

### ğŸ’« **Special Thanks**

</div>

<div align="center">

| **ğŸ¢ Organization** | **ğŸ¯ Contribution** |
|---------------------|-------------------|
| **Shell.ai Team** | Organizing this impactful hackathon and providing real-world industry challenges |
| **HackerEarth** | Excellent platform for hosting the competition with robust evaluation system |
| **Sustainable Energy Community** | Inspiration and motivation to work on clean energy solutions |
| **Open Source Community** | Amazing libraries and tools that made this solution possible |

</div>

---

*This project contributes to the global effort of accelerating sustainable fuel adoption and supporting the transition to a net-zero future.*